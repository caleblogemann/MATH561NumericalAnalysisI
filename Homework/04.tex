\documentclass[11pt]{article}
\usepackage[letterpaper, margin = .75in]{geometry}
\usepackage{MATH561}
\usepackage{SetTheory}
\usepackage{Derivative}
\usepackage{Vector}
\usepackage{Complex}
\allowdisplaybreaks


\begin{document}
\noindent \textbf{\Large{Caleb Logemann \\
MATH 561 Numerical Analysis I \\
Homework 4
}}

\begin{enumerate}
    \item[\#1] % Done
        \begin{enumerate}
            \item[(a)]
                Determine the principle error function of the general explicit
                two-stage Runge-Kutta method.

                The general explicit two-stage Runge-Kutta method can be
                described as follows.
                \begin{align*}
                    k_1 &= f(x,y) \\
                    k_2 &= f(x + \mu h, y + \mu h k_1) \\
                    \Phi(x, y; h) &= \alpha_1 k_1 + \alpha_2 k_2
                \end{align*}

                To find the priniciple error function, first the local
                truncation error must be found.
                The local truncation error is defined as
                \[
                    T(x, y; h) = \Phi(x, y; h) - \frac{1}{h}\p{y(x + h) - y(x)}
                \]
                The principle error function is the functional coefficient of $h^p$
                in the local truncation error, when $p$ is the order of the method.
                Two-stage Runge-Kutta methods have in general an order of $p = 2$,
                so the principle error function is the coefficient of $h^2$.
                In order to find this the Taylor expansion of $\Phi(x, y; h)$ and
                $\frac{1}{h}\p{y(x + h) - y(x))}$ must be found, at least to the 
                $h^2$ term.

                First I will find the Taylor expansion of
                $\Phi(x, y; h) = \alpha_1 k_1 + \alpha_2 k_2$.
                The Taylor expansion of $k_1 = f(x,y)$ is just $f(x,y)$.
                The Taylor expansion of $k_2$ can be found as follows.
                \begin{align*}
                    k_2 &= f(x + \mu h, y + \mu h k_1) \\
                    &= f(x + \mu h, y + \mu h f(x,y)) \\
                    &= f(x,y) + f_x(x, y)(\mu h) + f_y(x,y)(\mu h f(x,y)) \\
                        &+ \frac{1}{2}\p{f_{xx}(x,y) (\mu h)^2 + 2f_{xy}(x,y)(\mu^2 h^2 f(x,y))
                        + f_{yy}(x,y)(\mu^2 h^2 f(x,y)^2} + O(h^3) \\
                    &= f(x,y) + \mu \p{f_x(x,y) + f(x,y) f_y(x,y)} h \\
                        &+\frac{1}{2} \mu^2 \p{f_{xx}(x,y) + 2 f(x,y) f_{xy}(x,y) + f(x,y)^2 f_{yy}(x,y)} h^2
                        + O(h^3) \\
                \end{align*}
                Now the Taylor expansion of $\Phi(x, y; h)$ can be expressed as follows.
                Note that moving forward all values or derivatives of $f$ will be
                evaluated at $(x,y)$.
                Thus $f = f(x,y)$, $f_x = f_x(x,y)$, $f_y = f_y(x,y)$, and so on.
                \begin{align*}
                    \Phi(x,y;h) &= \alpha_1 k_1 + \alpha_2 k_2 \\
                    &= \alpha_1 f + \alpha_2 \p{f + \mu \p{f_x + f f_y} h +
                        \frac{1}{2} \mu^2 \p{f_{xx} + f f_{xy} + f^2 f_{yy}} h^2 + O(h^3)} \\
                    &= (\alpha_1 + \alpha_2) f + \mu \alpha_2 \p{f_x + f f_y} h + 
                        \frac{1}{2} \alpha_2 \mu^2 \p{f_{xx} + 2f f_{xy} + f^2 f_{yy}} h^2 + O(h^3)
                \end{align*}

                Now that the Taylor expansion of $\Phi(x, y; h)$ has been found
                the Taylor expansion of $\frac{1}{h}\p{y(x + h) - y(x))}$ must be
                found and put in terms of $f$.
                \begin{align*}
                    y(x + h) &= y(x) + h y'(x) + \frac{h^2}{2} y''(x) + \frac{h^3}{6} y'''(x) + O(h^4) \\
                    \frac{1}{h}\p{y(x + h) - y(x))} &= y'(x) + \frac{h}{2} y''(x) + \frac{h^2}{6} y'''(x) + O(h^3) \\
                    \intertext{Now note that $y'(x) = f(x,y)$, and the other derivatives of $y$ can be put in terms of $f$ as well.}
                    y''(x) &= f_x(x, y) f_y(x,y) y'(x) = f_x(x,y) + f_y(x,y) f(x,y) = f_x + f_y f \\
                    y'''(x) &= f_{xx} + f_{xy} f + f_y (f_x + f_y f) + f(f_{yx} + f_{yy} f) \\
                            &= f_{xx} + 2 f f_{xy} + f_x f_y + f f_y^2 + f^2 f_{yy}
                    \intertext{Therefore}
                    \frac{1}{h}\p{y(x + h) - y(x))} &= f + \frac{h}{2} \p{f_x + f_y f}
                        + \frac{h^2}{6}\p{f_{xx} + 2 f f_{xy} + f_x f_y + f f_y^2 + f^2 f_{yy}} + O(h^3)
                \end{align*}

                Finally the Taylor expansion of the local truncation error can be examined.
                \begin{align*}
                    T(x, y; h) &= (\alpha_1 + \alpha_2) f + \mu \alpha_2 \p{f_x + f f_y} h + 
                        \frac{1}{2} \alpha_2 \mu^2 \p{f_{xx} + 2 f f_{xy} + f^2 f_{yy}} h^2 \\
                        &-\p{f + \frac{h}{2} \p{f_x + f_y f}
                        + \frac{h^2}{6}\p{f_{xx} + 2 f f_{xy} + f_x f_y + f f_y^2 + f^2 f_{yy}}} + O(h^3) \\
                    &= (\alpha_1 + \alpha_2 - 1) f + \p{\mu \alpha_2 - \frac{1}{2}} \p{f_x + f f_y} h \\
                        &+ \p{\p{\frac{1}{2} \alpha_2 \mu^2 - \frac{1}{6}}\p{f_{xx} + 2 f f_{xy} + f^2 f_{yy}}
                        -\frac{1}{6}\p{f_x f_y + f f_y^2}} h^2 + O(h^3) \\
                \end{align*}

                For any general two-stage Runge-Kutta Method,
                $(\alpha_1 + \alpha_2 - 1) = 0$ and
                $\p{\mu \alpha_2 - \frac{1}{2}} = 0$.
                This implies that $\mu = \frac{1}{2 \alpha_2}$.
                Therefore the principle error function for any general
                two-stage Runge-Kutta method is
                \[
                    \tau(x,y) = \p{\frac{1}{8 \alpha_2}
                        -\frac{1}{6}}\p{f_{xx} + 2 f f_{xy} + f^2 f_{yy}}
                        -\frac{1}{6}\p{f_x f_y + f f_y^2}
                \]

            \item[(b)]
                Compare the local accuracy of the modified Euler method with
                that of Heun's method.

                For this specific ordinary differential equation,
                $f(x, y) = y^{\lambda}$.
                Thus
                \begin{align*}
                    f_x &= 0 \\
                    f_{xx} &= 0 \\
                    f_{xy} &= 0 \\
                    f_{y} &= \lambda y^{\lambda - 1} \\
                    f_{yy} &= \p{\lambda^2 - \lambda} y^{\lambda - 2}
                \end{align*}
                

                Therefore the principle error function becomes
                \begin{align*}
                    \tau(x,y) &= \p{\frac{1}{8 \alpha_2}
                        -\frac{1}{6}}\p{y^{2\lambda} \p{\lambda^2 - \lambda}y^{\lambda - 2}}
                        -\frac{1}{6}\p{y^{\lambda} \lambda^2 y^{2\lambda - 2}} \\
                    &= \p{\frac{1}{8 \alpha_2}
                        -\frac{1}{6}}\p{\p{\lambda^2 - \lambda} y^{3\lambda - 2}}
                        -\frac{1}{6}\p{\lambda^2 y^{3\lambda - 2}} \\
                    &= \p{\p{\frac{1}{8 \alpha_2}
                        -\frac{1}{6}}\p{\lambda^2 - \lambda} - \frac{1}{6} \lambda^2} y^{3\lambda - 2}
                \end{align*}

                For the improved Euler method, $\alpha_2 = 1$.
                Therefore the principle error function for the Euler method, $\tau_E$ is
                \begin{align*}
                    \tau_E(x, y) &= \p{\p{\frac{1}{8}-\frac{1}{6}}\p{\lambda^2 - \lambda} - \frac{1}{6} \lambda^2} y^{3\lambda - 2} \\
                    &= -\frac{1}{24}\p{5\lambda^2 - \lambda} y^{3\lambda - 2} \\
                \end{align*}

                For Heun's method, $\alpha_2 = \frac{1}{2}$.
                Therefore the principle error function for Heun's method, $\tau_H$ is
                \begin{align*}
                    \tau_H(x,y) &= \p{\p{\frac{1}{4}-\frac{1}{6}}\p{\lambda^2 - \lambda} - \frac{1}{6} \lambda^2} y^{3\lambda - 2} \\
                                &= -\frac{1}{12}\p{\lambda^2 + \lambda} y^{3\lambda - 2}
                \end{align*}

                For what values of $\lambda$ is the magnitude of the principle
                error function less Euler's method than Heun's method.
                For what values of $\lambda$ is $\abs{\tau_E} < \abs{\tau_H}$
                \begin{align*}
                    \abs{\tau_E(x,y)} &< \abs{\tau_H(x,y)} \\
                    \abs{-\frac{1}{24}\p{5\lambda^2 - \lambda} y^{3\lambda - 2}} &< \abs{-\frac{1}{12}\p{\lambda^2 + \lambda} y^{3\lambda - 2}} \\
                    \frac{1}{24}\abs{5\lambda^2 - \lambda} &< \frac{1}{12}\abs{\lambda^2 + \lambda} \\
                    \abs{5\lambda^2 - \lambda} &< 2\abs{\lambda^2 + \lambda} \\
                    \abs{\lambda\p{5\lambda - 1}} &< \abs{\lambda\p{2\lambda + 2}} \\
                \end{align*}
                Clearly $\abs{\lambda\p{5\lambda - 1}} = \abs{\lambda\p{2\lambda + 2}}$,
                when $\lambda = 0$.
                It is also equal when $\p{5\lambda - 1} = \p{2\lambda + 2}$,
                which implies that $\lambda = 1$.
                These are the only two points of intersection.
                When $\lambda = 2$, $\abs{\lambda\p{5\lambda - 1}} > \abs{\lambda\p{2\lambda + 2}}$
                and when $\lambda = \frac{1}{2}$, $\abs{\lambda\p{5\lambda - 1}} < \abs{\lambda\p{2\lambda + 2}}$.
                Therefore $\abs{\tau_E(x,y)} < \abs{\tau_H(x,y)}$ on $\lambda \in (0, 1)$, and
                $\abs{\tau_H(x,y)} < \abs{\tau_E(x,y)}$ on $\lambda \in (1, \infty)$.

            \item[(c)]
                Determine an interval of $\lambda$ such that for each
                $\lambda$ in this interval there exists a two-stage explicit
                Runge-Kutta method of order $p = 3$ having parameters
                $0 < \alpha_1 < 1$, $0 < \alpha_2 < 1$ and $0 < \mu < 1$.

                In order for a two stage explicit Runge-Kutta method to have
                order $p = 3$, the principle error function, $\tau(x,y)$, must
                be zero.

                We have previously determined that $\alpha_1 = 1 - \alpha_2$
                and $\mu = \frac{1}{2\alpha_2}$.
                Therefore for $0 < \alpha_1 < 1$, then $0 < \alpha_2 < 1$.
                Also for $0 < \mu < 1$, then $0 < \frac{1}{2\alpha_2} < 1$
                which implies that $\frac{1}{2} < \alpha_2 < \infty$.
                Therefore if $\frac{1}{2} < \alpha_2 < 1$, all three conditions
                will be met.

                In order for $\tau(x,y) = 0$,
                \begin{align*}
                    0 &= \p{\frac{1}{8 \alpha_2}-\frac{1}{6}}\p{\lambda^2 - \lambda} - \frac{1}{6} \lambda^2 \\
                    0 &= \p{\frac{1}{8 \alpha_2} -\frac{1}{3}}\lambda^2 - \p{\frac{1}{8 \alpha_2} -\frac{1}{6}}\lambda \\
                    0 &= \p{3 - 8\alpha_2} \lambda - 3 + 4\alpha_2 \\
                    \frac{3 - 4\alpha_2}{3 - 8\alpha_2} &= \lambda \\
                \end{align*}
                If $\frac{1}{2} < \alpha_2 < 1$, then $-1 < \lambda < \frac{1}{5}$.
                Since $\lambda > 0$, then for $0 < \lambda < \frac{1}{5}$ there exists
                an explicit two-stage Runge-Kutta method with order $p=3$ and with parameters
                between 0 and 1.
        \end{enumerate}

    \item[\#2] % Done
        Let $\v{f}(x,\v{y})$ satisfy a Lipschitz condition in $\v{y}$ on
        $\br{a,b} \times \RR^d$, with Lipschitz constant $L$.
        \begin{enumerate}
            \item[(a)] % Done
                Show that the increment function $\v{\Phi}$ of the second order
                Runge-Kutta method
                \begin{align*}
                    \v{k}_1 &= \v{f}(x, \v{y}) \\
                    \v{k}_2 &= \v{f}(x + h, \v{y} + h\v{k}_1) \\
                    \v{\Phi}(x, \v{y}; h) &= \frac{1}{2}(\v{k}_1 + \v{k}_2)
                \end{align*}
                also satisfies a Lipschitz condition whenever $x + h \in \br{a, b}$
                and determine a respective Lipschitz constant $M$.

                To show that $\v{\Phi}(x,\v{y}; h)$ satisfies a Lipschitz
                condition the value of $\norm{\v{\Phi}(x,\v{y}; h) - \v{\Phi}(x,\v{y}^*; h)}$
                must be shown to be bounded by a multiple of $\norm{y - y^*}$.
                For notational simplicity, I will define the following values
                \begin{align*}
                    \v{k}_1^* &= \v{f}(x, \v{y}^*) \\
                    \v{k}_2^* &= \v{f}(x + h, \v{y}^* + h\v{k}_1^*) \\
                    \v{\Phi} &= \v{\Phi}(x, \v{y}; h) \\
                    \v{\Phi}^* &= \v{\Phi}(x, \v{y}^*; h)
                \end{align*}

                Then
                \begin{align*}
                    \norm{\v{\Phi} - \v{\Phi}^*} &= \frac{1}{2}\norm{\v{k}_1 + \v{k}_2 - \v{k}_1^* - \v{k}_2^*} \\
                    &\le \frac{1}{2}\p{\norm{\v{k}_1 - \v{k}_1^*} + \norm{\v{k}_2 - \v{k}_2^*}}
                    \intertext{Now consider $\norm{\v{k}_1 - \v{k}_1^*}$}
                    \norm{\v{k}_1 - \v{k}_1^*} &= \norm{\v{f}(x, \v{y}) - \v{f}(x, \v{y}^*)}
                    \intertext{Since $f$ satisfies the Lipschitz condition}
                    \norm{\v{k}_1 - \v{k}_1^*} &\le L\norm{\v{y} - \v{y}^*}
                    \intertext{Next consider $\norm{\v{k}_2 - \v{k}_2^*}$}
                    \norm{\v{k}_2 - \v{k}_2^*} &= \norm{\v{f}(x + h, \v{y} + h\v{k}_1) - \v{f}(x + h, \v{y}^* + h\v{k}_1^*)}
                    \intertext{Since $f$ satisfies the Lipschitz condition}
                    \norm{\v{k}_2 - \v{k}_2^*} &\le L \norm{\v{y} + h\v{k}_1 - \v{y}^* - h\v{k}_1^*} \\
                    \norm{\v{k}_2 - \v{k}_2^*} &\le L \p{\norm{\v{y} - \v{y}^*} + h\norm{\v{k}_1 - \v{k}_1^*}}
                    \intertext{We have already shown that $\norm{\v{k}_1 - \v{k}_1^*} \le L\norm{\v{y} - \v{y}^*}$}
                    \norm{\v{k}_2 - \v{k}_2^*} &\le \p{L + hL^2} \norm{\v{y} - \v{y}^*}
                    \intertext{Therefore}
                    \norm{\v{\Phi} - \v{\Phi}^*} &\le \p{L + \frac{h}{2}L^2} \norm{\v{y} - \v{y}^*}
                \end{align*}
                Therefore $\v{\Phi}$ satisfies a Lipschitz condition and has
                Lipschitz constant, $M = L + \frac{h}{2}L^2$.

            \item[(b)] % Done
                Show that the classical fourth order Runge-Kutta method
                satisifies a Lipschitz condition.
                \begin{align*}
                    \v{k}_1 &= \v{f}(x,\v{y}) \\
                    \v{k}_2 &= \v{f}(x + \frac{1}{2}h,\v{y} + \frac{1}{2}h\v{k}_1) \\
                    \v{k}_3 &= \v{f}(x + \frac{1}{2}h,\v{y} + \frac{1}{2}h\v{k}_2) \\
                    \v{k}_4 &= \v{f}(x + h,\v{y} + h\v{k}_3) \\
                    \v{\Phi}(x,\v{y}; h) &= \frac{1}{6}\v{k}_1 + \frac{1}{3}\v{k}_2 + \frac{1}{3}\v{k}_3 + \frac{1}{6}\v{k}_4
                \end{align*}

                \begin{align*}
                    \norm{\v{\Phi} - \v{\Phi}^*} &\le \frac{1}{6}\norm{\v{k}_1 - \v{k}_1^*}
                        + \frac{1}{3}\norm{\v{k}_2 - \v{k}_2^*} + \frac{1}{3}\norm{\v{k}_3 - \v{k}_3^*}
                        + \frac{1}{6}\norm{\v{k}_4 - \v{k}_4^*}
                    \intertext{Now consider each of these norms individually}
                    \norm{\v{k}_1 - \v{k}_1^*} &= \norm{\v{f}(x,\v{y}) - \v{f}(x,\v{y}^*)} \\
                    &\le L\norm{\v{y} - \v{y}^*} \\
                    \norm{\v{k}_2 - \v{k}_2^*} &= \norm{\v{f}(x + \frac{1}{2}h,\v{y} + \frac{1}{2}h\v{k}_1) - \v{f}(x + \frac{1}{2}h,\v{y}^* + \frac{1}{2}h \v{k}_1^*)} \\
                    &\le L\norm{\v{y} + \frac{1}{2}h\v{k}_1 - \v{y}^* - \frac{1}{2}h\v{k}_1^*} \\
                    &\le L\norm{\v{y} - \v{y}^*} + \frac{1}{2}h L \norm{\v{k}_1 - \v{k}_1^*} \\
                    &\le (L + \frac{1}{2}hL^2)\norm{\v{y} - \v{y}^*} \\
                    \norm{\v{k}_3 - \v{k}_3^*} &= \norm{\v{f}(x + \frac{1}{2}h,\v{y} + \frac{1}{2}h\v{k}_2) - \v{f}(x + \frac{1}{2}h,\v{y}^* + \frac{1}{2}h\v{k}_2^*)} \\
                    &\le L\norm{\v{y} + \frac{1}{2}h\v{k}_2 - \v{y}^* - \frac{1}{2}h\v{k}_2^*} \\
                    &\le L\norm{\v{y} - \v{y}^*} + \frac{1}{2}hL\norm{\v{k}_2 - \v{k}_2^*} \\
                    &\le \p{L + \frac{1}{2}hL^2 + \frac{1}{4}h^2L^3}\norm{\v{y} - \v{y}^*} \\
                    \norm{\v{k}_4 - \v{k}_4^*} &= \norm{\v{f}(x + h,\v{y} + h\v{k}_3) - \v{f}(x + h,\v{y}^* + h\v{k}_3^*)} \\
                    &\le L \norm{\v{y} + h\v{k}_3 - \v{y}^* - h\v{k}_3^*} \\
                    &\le L \norm{\v{y} - \v{y}} + hL\norm{\v{k}_3 - \v{k}_3^*} \\
                    &\le L \norm{\v{y} - \v{y}^*} + \p{hL^2 + \frac{1}{2}h^2L^3 + \frac{1}{4}h^3L^4}\norm{\v{y} - \v{y}^*} \\
                    &= \p{L + hL^2 + \frac{1}{2}h^2L^3 + \frac{1}{4}h^3L^4}\norm{\v{y} - \v{y}^*} \\
                    \intertext{Let $M_1 = L$, $M_2 = L + \frac{1}{2}hL^2$,
                        $M_3 = L + \frac{1}{2}hL^2 + \frac{1}{4}h^2L^3$ and
                        $M_4 = L + hL^2 + \frac{1}{2}h^2L^3 + \frac{1}{4}h^3L^4$.
                        Then}
                    \norm{\v{\Phi} - \v{\Phi}^*} &\le \p{\frac{1}{6}M_1 + \frac{1}{3}M_2 + \frac{1}{3}M_3 + \frac{1}{6}M_4}\norm{\v{y} - \v{y}^*}
                \end{align*}
                Thus $\v{\Phi}$ does satisfy a Lipschitz condition and has a Lipschitz constant of
                $M = \frac{1}{6}M_1 + \frac{1}{3}M_2 + \frac{1}{3}M_3 + \frac{1}{6}M_4$.

            \item[(c)] % Done
                Show that $\v{\Phi}$ for a general implicit Runge-Kutta method
                satisfies a Lipschitz condition.

                For a general implicit Runge-Kutta method,
                $\v{\Phi}(x,\v{y}; h) =  \sum{s=1}{r}{\alpha_s \v{k}_s}$, where
                $\v{k}_s = f(x + \mu_s h, \v{y} + h\sum{j=1}{r}{\lambda_{sj} \v{k}_j})$.
                I will continue to use the previously established notation.
                \begin{align*}
                    \norm{\v{\Phi} - \v{\Phi}^*} &= \norm{\sum{s=1}{r}{\alpha_s \v{k}_s} - \sum{s=1}{r}{\alpha_s \v{k}_s^*}} \\
                    &\le \sum{s=1}{r}{\alpha_s \norm{\v{k}_s - \v{k}_s^*}}
                    \intertext{Now consider a single value of $\norm{\v{k}_s - \v{k}_s^*}$}
                    \norm{\v{k}_s - \v{k}_s^*} &= \norm{f(x + \mu_s h, \v{y} + h\sum{j=1}{r}{\lambda_{sj} \v{k}_j}) - f(x + \mu_s h, \v{y}^* + h\sum{j=1}{r}{\lambda_{sj} \v{k}_j^*})}
                    \intertext{Since $f$ satisfies a Lipschitz condition}
                    \norm{\v{k}_s - \v{k}_s^*} &\le L \norm{\v{y} + h\sum{j=1}{r}{\lambda_{sj} \v{k}_j} - \v{y}^* - h\sum{j=1}{r}{\lambda_{sj} \v{k}_j^*}} \\
                    &\le L \norm{\v{y} - \v{y}^*} + hL \norm{\sum{j=1}{r}{\lambda_{sj} \v{k}_j} -\sum{j=1}{r}{\lambda_{sj} \v{k}_j^*}}
                    \intertext{Let $\Gamma$ be the max of $\lambda_{sj}$ for $s,j = 0, \ldots, r$}
                    \norm{\v{k}_s - \v{k}_s^*} &\le L \norm{\v{y} - \v{y}^*} + hL\Gamma \sum{j=1}{r}{\norm{\v{k}_j\v{k}_j^*}} \\
                    \intertext{Summing both side from $s = 1$ to $r$ results in}
                    \sum{s=1}{r}{\norm{\v{k}_s - \v{k}_s^*}} &\le sL \norm{\v{y} - \v{y}^*} + shL\Gamma \sum{j=1}{r}{\norm{\v{k}_j\v{k}_j^*}} \\
                    \sum{s=1}{r}{\norm{\v{k}_s - \v{k}_s^*}} &\le \frac{sL}{1 - shL\Gamma} \norm{\v{y} - \v{y}^*}
                    \intertext{Now consider $\norm{\v{\Phi} - \v{\Phi}^*}$, and let $A$ be the max of $\alpha_s$ for $s = 1, \ldots, n$}
                    \norm{\v{\Phi} - \v{\Phi}^*} &\le A \sum{s=1}{r}{\norm{\v{k}_s - \v{k}_s^*}} \\
                    &\le \frac{AsL}{1 - shL\Gamma} \norm{\v{y} - \v{y}^*}
                \end{align*}
                Therefore $\v{\Phi}$ does satisfy a Lipschitz condition and has
                a Lipschitz constant of $\frac{AsL}{1 - shL\Gamma}$.
        \end{enumerate}

    \item[\#3]
        Consider $y' = \lambda y$ on $[0, \infty)$ for complex $\lambda$ with
        $\Re(\lambda) < 0$.
        Let $\set{u_n}$ be the approximations of $\set{y(x_n)}$ obtained by
        the classical fourth-order Runge-Kutta method with the step $h$ held
        constant.
        \begin{enumerate}
            \item[(a)] % Done
                Show that $y(x) \to 0$ as $x \to \infty$, for any initial
                value $y_0$.

                This ODE can be solved exactly for any initial condition $y_0$.
                The exact solution is $y(x) = y_0 e^{\lambda x}$.
                This is equivalent to $y(x) = y_0 e^{\Re{\lambda}x} e^{\Im{\lambda} i x}$.
                For all $x$ and all $\lambda$, $\abs{e^{\Im{\lambda} i x}} = 1$.
                Also since $\Re(\lambda) < 0$, $e^{\Re{\lambda}x} \to 0$ as $x \to \infty$,
                then $y(x) \to 0$ as $x \to \infty$.

            \item[(b)]
                Under what condition on $h$ can we assert that $u_n \to 0$ as
                $n \to \infty$?
                In particular what is the condition if $\lambda$ is real.

                To determine if $u_n \to 0$ as $n \to \infty$, the function $\phi(x,y;h)$
                must be considered, because $u_n = \phi(x,y;h) u_{n-1}$.
                That is if $\abs{\phi(x,y;h)} < 1$, then $u_n \to 0$ when
                $n \to \infty$.
                \begin{align*}
                    \phi(h\lambda)y &= y + h\Phi(x,y;h) \\
                    \Phi(x,y;h) &= \frac{1}{6} k_1 + \frac{1}{3}k_2 + \frac{1}{3}k_3 + \frac{1}{6}k_4 \\
                    k_1 &= f(x,y) \\
                        &= \lambda y \\
                    k_2 &= f(x + \frac{1}{2}h, y + \frac{1}{2}h k_1) \\
                        &= \lambda(y + \frac{1}{2}h \lambda y) \\
                        &= \lambda y + \frac{1}{2} h \lambda^2 y \\
                        &= (\lambda + \frac{1}{2} h \lambda^2) y \\
                    k_3 &= f(x + \frac{1}{2}h, y + \frac{1}{2} h k_2) \\
                        &= \lambda(y + \frac{1}{2} h k_2) \\
                        &= \lambda(y + \frac{1}{2} h (\lambda y + \frac{1}{2} h \lambda^2 y)) \\
                        &= \lambda y + \frac{1}{2} h \lambda^2 y + \frac{1}{4} h^2 \lambda^3 y \\
                        &= (\lambda + \frac{1}{2} h \lambda^2 + \frac{1}{4} h^2 \lambda^3) y \\
                    k_4 &= f(x + h, y + h k_3) \\
                        &= \lambda(y + h (\lambda + \frac{1}{2} h \lambda^2 + \frac{1}{4} h^2 \lambda^3) y) \\
                        &= (\lambda + h \lambda^2 + \frac{1}{2} h^2 \lambda^3 + \frac{1}{4} h^3 \lambda^4) y \\
                    \Phi(x,y;h) &= \p{\frac{1}{6} \lambda + \frac{1}{3}(\lambda + \frac{1}{2} h \lambda^2) +
                        \frac{1}{3}(\lambda + \frac{1}{2} h \lambda^2 + \frac{1}{4} h^2 \lambda^3) + 
                        \frac{1}{6}(\lambda + h \lambda^2 + \frac{1}{2} h^2 \lambda^3 + \frac{1}{4} h^3 \lambda^4)} y \\
                        &= \p{\lambda + \frac{1}{2} h \lambda^2 + \frac{1}{6} h^2 \lambda^3 + \frac{1}{24} h^3 \lambda^4} y \\
                    \phi(h\lambda) &= 1 + h\lambda + \frac{1}{2} h^2 \lambda^2 + \frac{1}{6} h^3 \lambda^3 + \frac{1}{24} h^4 \lambda^4
                    \phi(z) &= 1 + z + \frac{1}{2} z^2 + \frac{1}{6} z^3 + \frac{1}{24} z^4
                \end{align*}
                This in order for $\abs{\phi(z)} < 1$,
                $\abs{1 + z + \frac{1}{2} z^2 + \frac{1}{6} z^3 + \frac{1}{24} z^4} < 1$
                This cannot be solved exactly easily.
                Using Mathematica is can be found that if $-2.7859 < z < 0$, then $\abs{\phi(z)} < 1$
                Therefore for $u_n \to 0$ as $n \to \infty$, $0 < h < -2.7859/\lambda$.

            \item[(c)]
                What is the analogous result for Euler's method.

                For Euler's method
                \begin{align*}
                    \Phi(x,y;h) &= f(x,y) \\
                    &= \lambda y
                    \phi(h\lambda) &= 1 + h\lambda \\
                    \phi(z) & = 1 + z \\
                \end{align*}
                Thus in order for $\abs{\phi(z)} < 1$, $-2 < z < 0$.
                Therefore for $u_n \to 0$ as $n \to \infty$, $0 < h < -2/\lambda$.

            \item[(d)]
                Generalize to a system $\v{y}' = A\v{y}$, where $A$ is a
                constant matrix with eigenvalues with negative real parts.

                For this generalized system, the equations of $\phi(z)$ stay the
                same, and we are considering $hA$ instead of $h\lambda$.
                Also note that using recursion $u_n = \phi(hA)^n u_0$.
                Therefore for $u_n \to 0$ as $n \to \infty$,
                $\abs{\phi(hA)^n} \to 0$ as $n \to \infty$.
                In order for the matrix $\abs{\phi(hA)^n}$ to converge to
                the zero matrix, the spectral radius of $\phi(hA)$, $\rho(\phi(hA))$
                must be less than one.
                The spectral radius is the maximum of the absolute values of the eigenvalues.
                Thus for $u_n \to \infty$ as $n \to \infty$, $\rho(\phi(hA)) < 1$.
                Also it is known that since $\phi$ is a polynomial, $\rho(\phi(hA)) = \abs{\phi(h\rho(A))}$

                For the classical fourth-order Runge-Kutta method, 
                we have already shown that $\abs{\phi(h\lambda)} < 1$ implies
                that $0 < h < \frac{-2.7859}{\lambda}$.
                Therefore for $\abs{\phi(h\rho(A))} < 1$, $0 < h < \frac{-2.7859}{\rho(A)}$.
                Since for all eigenvalues, $\lambda_i$ of $A$, $\abs{\lambda_i} \le \rho(A)$,
                this implies that $0 < h < \frac{-2.7859}{\lambda_i}$ for all eigenvalues
                of $A$.

                Similarly for Euler's method,
                $0 < h < \frac{-2}{\rho(A)} < \frac{-2}{\lambda_i}$.
                Thus the value of h is related to the spectral radius of $A$.

        \end{enumerate}

    \item[\#4]
        Consider the linear homogeneous system
        \[
            \v{y}' = A\v{y}\text{, }y \in \RR^d
        \]
        with constant coefficient matrix $A \in \RR^{d \times d}$
        \begin{enumerate}
            \item[(a)]
                For Euler method applied to this system, determine $\phi(z)$ and
                the principle error function.

                We have previously determined in problem 3, that $\phi(z) = 1 + z$
                for this method on this system.
                In order to find the principe error function the local truncation
                error must be computed.
                The local truncation error is given by
                $T(x,\v{y}; h) = \frac{1}{h}\p{\phi(hA) - e^{hA}} \v{y}$
                \begin{align*}
                    T(x,\v{y}; h) &= \frac{1}{h}\p{1 + hA - e^{hA}} \v{y}
                    \intertext{Taking the Taylor expansion of $e^{hA}$}
                    T(x,\v{y}; h) &= \frac{1}{h} \p{1 + hA - 1 - hA - \frac{1}{2} (hA)^2 - O((hA)^3)} \v{y} \\
                                  &= \p{-\frac{1}{2} hA^2 - O(h^2)} \v{y}
                    \intertext{Therefore Euler's method is of order 1 and has
                    principle error function}
                    \tau(x,y) &= -\frac{1}{2}A^2\v{y}
                \end{align*}

            \item[(b)]
                Do the same for the classical fourth-order Runge-Kutta method.

                We have previously shown in problem 3, that
                $\phi(z) = 1 + z + \frac{1}{2}z^2 + \frac{1}{3!}z^3 + \frac{1}{4!}z^4$,
                for this problem and the classical fourth-order Runge-Kutta's method.
                Again to find the principle error function the local truncation error
                must be computed.
                \begin{align*}
                    T(x,\v{y}; h) &= \frac{1}{h}\p{1 + hA + \frac{1}{2}(hA)^2 + \frac{1}{3!}(hA)^3 + \frac{1}{4!}(hA)^4 - e^{hA}} \v{y}
                    \intertext{Taking the Taylor expansion of $e^{hA}$ and canceling terms results in}
                    T(x,\v{y}; h) &= \frac{1}{h}\p{-\frac{1}{5!}h^5A^5 + O(h^6)}\v{y}
                    &= \p{\frac{1}{5!}h^4A^5 + O(h^5)} \v{y}
                    \intertext{Therefore the classical fourth-order Runge-Kutta method
                        has order 4 and principle error function}
                    \tau(x,\v{y}) &= \frac{1}{120} A^5 \v{y}
                \end{align*}
        \end{enumerate}

    \item[\#5]
        \begin{enumerate}
            \item[(a)]
                I created a set of objects to represent different methods of
                solving a system of ODEs
                The most general object represents explicit one-step methods
                and is able to apply to method to approximate the system with the function
                solveSystem.m.
                Look specifically as the functions solveSystem.m and phi.m to see the inner workings
                of this system.
                \lstinputlisting[language=Matlab]{../+NumericalAnalysis/+ODES/@explicitOneStepMethod/explicitOneStepMethod.m}
                \lstinputlisting[language=Matlab]{../+NumericalAnalysis/+ODES/@explicitOneStepMethod/solveSystem.m}

                I created another object to be able to represent any explicit Runge-Kutta method,
                and implemented the $\Phi$ method.
                \lstinputlisting[language=Matlab]{../+NumericalAnalysis/+ODES/@explicitRungeKuttaMethod/explicitRungeKuttaMethod.m}
                \lstinputlisting[language=Matlab]{../+NumericalAnalysis/+ODES/@explicitRungeKuttaMethod/phi.m}

                Lastly there are objects to actually represent Euler's method and the
                classical fourth-order Runge-Kutta method.
                \lstinputlisting[language=Matlab]{../+NumericalAnalysis/+ODES/@eulerMethod/eulerMethod.m}
                \lstinputlisting[language=Matlab]{../+NumericalAnalysis/+ODES/@standardRK4Method/standardRK4Method.m}

            \item[(b)]
                This is the script that actually uses these object to solve the system
                \lstinputlisting[language=Matlab]{H04.m}
                \begin{verbatim}
eulerError =

   0.669647499864682
   0.433642339396205
   0.294149701224462
   0.203833950720079
   0.142702928842803


rkError =

   1.0e-03 *

   0.172958606434202
   0.009918694490326
   0.000715540503618
   0.000057312979472
   0.000004825933441


eulerError =

   1.0e+12 *

   0.000000575152398
   0.001922582741375
   1.643413090818388
   0.000084922547445
   0.000000000000952


rkError =

   1.0e+24 *

   0.000000065788346
   1.537651043959767
   0.553810514762947
   0.000000000000000
   0.000000000000000
                \end{verbatim}

                I learned from these examples that for stiff problems
                even good numerical methods can become very unstable
                if $h$ is not in the region of A-stabity.
                In the stiff problem both methods have extremely large error.
                It is interesting to note that the Runge-Kutta method
                has much larger error for this stiff problem than
                Euler's method.
                This seems to indicate that when they are both
                unstable the Runge-Kutta method is much more unstable.
                However once method is unstable the magnitude of the
                error is not really important.
                The Runge-Kutta method has a larger region of A-stability.
                You can see that the error drops to almost 0, once
                h enters the region of A-stability.
                A much smaller h is required for this to happen
                with Euler's method.

                Also for the nonstiff problem, not how much smaller the
                error is for Runge-Kuttas method.
                It is also possible to see the error in Runge-Kutta's
                method is divided by 64 as $h$ is cut in
                half.
                For Euler's method the error does not even decrease
                by half as $h$ is cut in half.
                This indicates that Runge-Kutta's method is of order 4
                and Euler's method is of order 1, as we previously have
                shown.
        \end{enumerate}
\end{enumerate}
\end{document}
